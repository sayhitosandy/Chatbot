800/800 [==============================] - 29s 37ms/step - loss: 2.8505 - val_loss: 2.8185              Epoch 2/30                                                                                              800/800 [==============================] - 27s 34ms/step - loss: 2.3941 - val_loss: 2.3766              Epoch 3/30                                                                                              800/800 [==============================] - 28s 35ms/step - loss: 2.1856 - val_loss: 2.3425              Epoch 4/30                                                                                              800/800 [==============================] - 28s 35ms/step - loss: 2.1097 - val_loss: 2.3252              Epoch 5/30                                                                                              800/800 [==============================] - 28s 35ms/step - loss: 2.0392 - val_loss: 2.2806              Epoch 6/30                                                                                              800/800 [==============================] - 26s 33ms/step - loss: 1.9789 - val_loss: 2.2864              Epoch 7/30                                                                                              800/800 [==============================] - 26s 33ms/step - loss: 1.9284 - val_loss: 2.2888              Epoch 8/30                                                                                              800/800 [==============================] - 26s 33ms/step - loss: 1.8853 - val_loss: 2.2920              Epoch 9/30                                                                                              800/800 [==============================] - 27s 34ms/step - loss: 1.8270 - val_loss: 2.2767              Epoch 10/30                                                                                             800/800 [==============================] - 28s 34ms/step - loss: 1.7639 - val_loss: 2.3132              Epoch 11/30                                                                                             800/800 [==============================] - 27s 33ms/step - loss: 1.7004 - val_loss: 2.3285              Epoch 12/30                                                                                             800/800 [==============================] - 27s 33ms/step - loss: 1.6230 - val_loss: 2.3254              Epoch 13/30                                                                                             800/800 [==============================] - 27s 33ms/step - loss: 1.5473 - val_loss: 2.3742              Epoch 14/30                                                                                             800/800 [==============================] - 27s 33ms/step - loss: 1.4616 - val_loss: 2.4100              Epoch 15/30                                                                                             800/800 [==============================] - 27s 34ms/step - loss: 1.3694 - val_loss: 2.4623              Epoch 16/30                                                                                             800/800 [==============================] - 27s 34ms/step - loss: 1.2819 - val_loss: 2.4427              Epoch 17/30                                                                                             800/800 [==============================] - 27s 34ms/step - loss: 1.1870 - val_loss: 2.4876              Epoch 18/30                                                                                             800/800 [==============================] - 27s 33ms/step - loss: 1.1032 - val_loss: 2.5311              Epoch 19/30                                                                                             800/800 [==============================] - 27s 34ms/step - loss: 1.0288 - val_loss: 2.5710              Epoch 20/30                                                                                             800/800 [==============================] - 27s 34ms/step - loss: 0.9466 - val_loss: 2.5730              Epoch 21/30                                                                                             800/800 [==============================] - 27s 34ms/step - loss: 0.8738 - val_loss: 2.6445              Epoch 22/30                                                                                             800/800 [==============================] - 27s 34ms/step - loss: 0.8124 - val_loss: 2.6839              Epoch 23/30                                                                                             800/800 [==============================] - 27s 33ms/step - loss: 0.7503 - val_loss: 2.6318              Epoch 24/30                                                                                             800/800 [==============================] - 27s 34ms/step - loss: 0.6996 - val_loss: 2.6561              Epoch 25/30                                                                                             800/800 [==============================] - 27s 34ms/step - loss: 0.6526 - val_loss: 2.6998              Epoch 26/30                                                                                             800/800 [==============================] - 27s 33ms/step - loss: 0.6040 - val_loss: 2.6928              Epoch 27/30                                                                                             800/800 [==============================] - 27s 34ms/step - loss: 0.5635 - val_loss: 2.7131              Epoch 28/30                                                                                             800/800 [==============================] - 27s 34ms/step - loss: 0.5248 - val_loss: 2.7288              Epoch 29/30                                                                                             800/800 [==============================] - 27s 34ms/step - loss: 0.4908 - val_loss: 2.7317              Epoch 30/30                                                                                             800/800 [==============================] - 27s 34ms/step - loss: 0.4594 - val_loss: 2.7799              Saving...                                                                                               C:\Users\Vishal\Anaconda3\envs\tensorflow-gpu\lib\site-packages\keras\engine\topology.py:2344: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).                                                                                                    str(node.arguments) + '. They will not be included '                                                  -                                                                                                       Input sentence:  not the hacking and gagging and spitting part. please.                                 Decoded sentence:  saved your ass convict. <UNK> <UNK>                                                  -                                                                                                       Input sentence:  you re asking me out. that s so cute. what s your name again?                          Decoded sentence:  got a lot to the the right? <UNK>                                                    -                                                                                                       Input sentence:  gosh if only we could find kat a boyfriend...                                          Decoded sentence:  that s just you a to to the ve                                                       -                                                                                                       Input sentence:  c esc ma tete. this is my head                                                         Decoded sentence:  d like to get with with you? <UNK>                                                   -                                                                                                       Input sentence:  that s because it s such a nice one.                                                   Decoded sentence:  dorsey can get the girl? <UNK>                                                       -                                                                                                       Input sentence:  how is our little find the wench a date plan progressing?                              Decoded sentence:  get the other <UNK> <UNK> <UNK>                                                      -                                                                                                       Input sentence:  you have my word. as a gentleman                                                       Decoded sentence:  re re for my she <UNK> <UNK> <UNK>                                                   -                                                                                                       Input sentence:  how do you get your hair to look like that?                                            Decoded sentence:  why should you? <UNK> <UNK> <UNK>                                                    -                                                                                                       Input sentence:  sure have.                                                                             Decoded sentence:  a could <UNK> <UNK> <UNK> <UNK>